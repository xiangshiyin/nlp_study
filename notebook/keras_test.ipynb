{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='pip install keras', returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run('pip install keras',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 0s 0us/step\n",
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(enumerate(chars))\n",
    "# x = [1,2,3]\n",
    "# x=(1,2,3)\n",
    "# x[1]=4\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# char_indices['0']\n",
    "indices_char[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '!', '\"', \"'\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface\\n\\n\\nsupposing that truth is a woma'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face\\n\\n\\nsupposing that truth is a woman--'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e\\n\\n\\nsupposing that truth is a woman--wha'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.float32)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.float32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 13:45:04.467819 140167486928704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0623 13:45:04.480506 140167486928704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0623 13:45:04.487758 140167486928704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 13:45:04.689678 140167486928704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0623 13:45:04.696448 140167486928704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Embedding(len(chars),10))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dropout())\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 57)                7353      \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 13:45:20.253279 140167486928704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0623 13:45:20.767812 140167486928704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200285/200285 [==============================] - 100s 497us/step - loss: 1.9591\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"longer praise, no longer blame, for it i\"\n",
      "longer praise, no longer blame, for it is and and the seen and the seen and the some and the artight of the present of the some of the same the some of a so the conscience of the rearly and the believed the morality and the sear and man conscience of the mand and the believed the really and and and the seen and the something the believed the seen and the some of the seen the subjects and and and the conscience of the seen and the so man\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"longer praise, no longer blame, for it i\"\n",
      "longer praise, no longer blame, for it is and resilitations there is and the seems the most philosophers the man and inspectations to he is a senses as this seen the constant and a poration of the present and \"and considerness of their disfect of the manding and sense and master to a callity and alinet the respect to be the something and the from and which it is at man\n",
      "in that be and in present of a mankind that is the sake and the all \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"longer praise, no longer blame, for it i\"\n",
      "longer praise, no longer blame, for it is a versine, romanfrat chiptian\" ent epophitys and imquestioning acts, their newment, all be is remary on stophart now the ibpames cheoppye of the exesure. dear pinity of thing evil aly this \"man's, themself the someren of\n",
      "there have stronger in very being ipshed\n",
      "astigation, is aspeceronations it diy see-mais more whather tveil re.ces everywais to the \"senfuament theiarne-not phorhered all st in t\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"longer praise, no longer blame, for it i\"\n",
      "longer praise, no longer blame, for it is to autening prebouly this colmanitys and inthipt andignxphing they mappecectuuls'e nok of isk--recient carm for, there i alta05 l. he and lutbodly its elom, their man; ont charsom dayle see. and differsble dompating \"myechroun-cwaienatiof. as least of suppeceing tysichegy austepps hay more apclised to te.\n",
      "choresicy coulto and this, sollent forthered by dasser, reaver ceepletss--and in adys will \n",
      "Epoch 2/5\n",
      "200285/200285 [==============================] - 99s 494us/step - loss: 1.6197\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"an and isolde\"--what all these enjoy, an\"\n",
      "an and isolde\"--what all these enjoy, and and the sentiment of the stands in the present and the stands and and and of the present the strength of the strength of the same the strength of the stands of the stands of the strength of the person of the ancerain of the strength of the stands of the problem of the strength and interpretation of the present of the stands of the stands of the theresting of an and the strength of the science of\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"an and isolde\"--what all these enjoy, an\"\n",
      "an and isolde\"--what all these enjoy, and of the possible of the man superions of the interpretation, and the self-the speally and interligated the contradication of the therefore that the stands to such a way and of the more and sacrification of every understood\" and loved of more and of the happiness and lacture in the delight and the higher contract the stranger, and and doupt of the stands which so him in the order to beand of the w\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"an and isolde\"--what all these enjoy, an\"\n",
      "an and isolde\"--what all these enjoy, and\n",
      "for innestrats of\n",
      "trouts,\n",
      "one hond he cause they, an\n",
      "-rightness or sub;nient of the xiving tydan\n",
      "artamed at arips, than what erape\n",
      "tiousnespless of certainably with actsious its lood a atcerx: which speap othisto . them\n",
      "ezerdaniousalinafute the plason recalamed retaphy to his what wluch \"clivartes--and dystrbing. the oteritly, viet\n",
      "eyvaciing--natele--bsion ham in undanceing--the still which they\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"an and isolde\"--what all these enjoy, an\"\n",
      "an and isolde\"--what all these enjoy, and like. weight is of statesmelr\n",
      "where belief what ac1ed which in the\n",
      "centain\n",
      "on prosenn tooget knowg,. herding afterrable \"protrending to could realer arts harminalments himan value of the man ofly noisfusude strepres\n",
      "nated the fact of general mancrythness and he whate\n",
      "for the worscaiurous rarr-guriess one\" apst-pe-moding soughai. there to perhap ho\n",
      "ghist\n",
      "chana we of\n",
      ";  eaching enear and mknessira\n",
      "Epoch 3/5\n",
      "200285/200285 [==============================] - 99s 493us/step - loss: 1.5363\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" fighting with wild beasts, simply to at\"\n",
      " fighting with wild beasts, simply to at the consided to the sense of the conscience and and the conception of the personal and the spiritual and the proved and the spiritual and the consided of the man and the most stand to the great means of the senses of the being the consided and the truth, the self-and to the stands of the subjection of the sense of the soul and the sense of the self-more and and and and and as a man and the senses\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" fighting with wild beasts, simply to at\"\n",
      " fighting with wild beasts, simply to at the intentions, and not on are standing too a mader, the present has the probariness and the probading the soul and so many and being to the most sturt the strength of the being development of the wolld been one: when as belief in the creation of the intellect of the senses and often and the respect of the other to the have the suffering and to the conception of the theen and one and so man.\" or \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" fighting with wild beasts, simply to at\"\n",
      " fighting with wild beasts, simply to at philosophers,\n",
      "ideable for cularer\", for\n",
      "fanized of were its extent speelory one probosyseded\"\n",
      "promityed exguise founl, othests,\n",
      "certial curned them enless proctedly in char in the oneshessy and are begin conceriation to so-whgaprible, and now secreceds of\n",
      "be \"four necessary and enful li\n",
      "cixk\n",
      "ye us althourms breamuled be\n",
      "the catter fett\n",
      "is imputies, for the realost and bespetious modec-providude:,\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" fighting with wild beasts, simply to at\"\n",
      " fighting with wild beasts, simply to at were\n",
      "alneselfolofk own thus preauprules\n",
      "yet overwasted and, as is to this his a\n",
      "charm. upon theist\". he oy you reached ean\"? the own probaded histxattitations of the world my honefty, bewaih of\n",
      "a\n",
      "\"childue--sufferous\n",
      "emble,\" there he dulour, personariove and even of\n",
      "rechorth them, ho\n",
      "anowhert an awaurated enthdent,\" oned\n",
      "as\n",
      "in, elfests, the dividiation of\n",
      "measube\n",
      "onl, the shig: urtae, as too sa\n",
      "st\n",
      "Epoch 4/5\n",
      "200285/200285 [==============================] - 101s 504us/step - loss: 1.4932\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e every day christian\n",
      "is a pitiable figu\"\n",
      "e every day christian\n",
      "is a pitiable figured that any the strength and its consequently and all the subtle and strong the problem and the subtle and the will of the stand and a strong the stand and strong and its of the obstreated and the will and all the superficiality of the principation of the first and the consequently the strong the strength the subtle and such an ance of the strong the strong the will to the considered the subtle i\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e every day christian\n",
      "is a pitiable figu\"\n",
      "e every day christian\n",
      "is a pitiable figure to a subtly and states and the to who is the our of the constitution and deceive and delight of a religious but influed of\n",
      "the the strong the interpreted to a not unterstance and us a patient to all fort and understand--and one not is all interpretet of the\n",
      "whole and almost the really for enomely as cause as one someten and all the such according the case this interpretentation and one will him\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e every day christian\n",
      "is a pitiable figu\"\n",
      "e every day christian\n",
      "is a pitiable figutely are been us a yeamed nam. than it relieated one! its\n",
      "philosophy among by motion and t.\n",
      "and want. to make scientific that ; every hardness the expression tran;\n",
      " . the time today forw respectations the\n",
      "erafice here. the heow, or wrangly to a man--but its man, for the\n",
      "amwafyed who noilove, the worch, is me\n",
      "tro:\n",
      "munuficable a distreation, knowledge notiste, that, he\n",
      "has steelien itherors tapennes\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e every day christian\n",
      "is a pitiable figu\"\n",
      "e every day christian\n",
      "is a pitiable figur imiling.le\n",
      "litely,ing, sould relised anoteli\n",
      "un as thein inme-manificureung is a footbryon envicais, \"but poweg cake,fil.\n",
      "sufforn? than that\n",
      "thir is\n",
      "perso\n",
      "vemulies type,--why beaunablic opport nevey, into homan\n",
      "dsy. overyated, byaposd.\n",
      "\n",
      "     reducationalis will ire able hmaccy,\"--there\n",
      "in this hacastolicis with but emporiore they and uncally--like germent of racees, =eam\n",
      "a  great amorave\n",
      "cure, t\n",
      "Epoch 5/5\n",
      "200285/200285 [==============================] - 100s 502us/step - loss: 1.4677\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rable romanticism, as if it were a begin\"\n",
      "rable romanticism, as if it were a begins of the presented and still the present that is self-derelighted the same interenceation of the possibility of the sensiations of the the for the period that is the same for the most the presented to the facts of the presented and does he can has been and commander the present that is still the religious morality of the stand of the same that and still the possibility of the same moral the philos\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rable romanticism, as if it were a begin\"\n",
      "rable romanticism, as if it were a begins the consequent to maintering the same of least and will to be the possibility ope of the presenting and instill and community and reason of many is the presention and the them, and the power of distrees of the power, and the still is which the ears of its consisteristic of the new preased to the\n",
      "long and common when deed to the presenter to a the proterted the most stand for the \"morals and ever\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rable romanticism, as if it were a begin\"\n",
      "rable romanticism, as if it were a begins otherful all perhaps naching never xalcater: yough and them,\n",
      "illf possicate fears, might and\n",
      "immorals. is interrongly day to the historors namely his worce of this ogh domain os--is, psifourionm in\n",
      "(as who has beerismen fundity still blend in,\n",
      "solitude: hoover naturally unfersurations: the eight tassefuially alone is sympthes of elemar to as will up\n",
      "as a worst that feeled unpid; name requiran ow\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rable romanticism, as if it were a begin\"\n",
      "rable romanticism, as if it were a begin) to philosophers poges. chuld or ie, is\n",
      "such thin is, a spirittled, less general tere ain vartalc: geopler who\n",
      "var atterianesh, molagether and very virtistational spirits of worsthomars every for a replacos\n",
      "forced is herd to incline\n",
      "towarkers acfuirorivatipation, uso in religious bothive--that too-ought beings--refiriols regardations with the buls more more also tyne--pabblefeless nothing extinut\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a94c781d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
